{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b3KGgph6MkR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import VivitImageProcessor, VivitForVideoClassification\n",
        "np.random.seed(0)\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the path to the new sample pairs CSV file, adjust it if needed\n",
        "new_csv_file_path = \"../Dataset/new_solid.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oTWFWNJV5nLY",
        "outputId": "094d48ea-a3dd-45f4-bfd8-be6fdf903027"
      },
      "outputs": [],
      "source": [
        "# get the name and parent folder path in 'start_frame'\n",
        "\n",
        "def get_file_name_and_parent_folder(file_path):\n",
        "  file_name = file_path.split('/')[-1].split('.')[0]\n",
        "  parent_folder = '/'.join(file_path.split('/')[:-1])\n",
        "  return file_name, parent_folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21midtGG4NiP",
        "outputId": "44a558dc-b265-4b12-ff17-20138e45c5c2"
      },
      "outputs": [],
      "source": [
        "class_labels =['down','same','up']\n",
        "label2id = {label: i for i, label in enumerate(class_labels)}\n",
        "id2label = {i: label for label, i in label2id.items()}\n",
        "print(f\"Unique classes: {list(label2id.keys())}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "593975c3684e477b8f8401d8d571f06d",
            "e969f77d7eb1440d92e1268a2df1a37f",
            "82fdbb9fbfd0490f9bec2d5edd0fa789",
            "c58d5e8298cb432aa9f67cad091498ed",
            "292a7e5a68094eb98ca3353dcff5c95e",
            "57568d0f8b844d2a9de59b973f2cf656",
            "cc72ba0cbcef40ce8d9c82432487f7b7",
            "a46e31db691642d49fe5eed5dc1c4ad1",
            "c70ad00e07e743b694a4ea19fcf8366f",
            "de740fe7dc004b6c8d0b7398747e19c9",
            "22947679820b45cb8a9322acb563e384"
          ]
        },
        "id": "SYjCRV0t4ACj",
        "outputId": "a06247f1-5455-4341-ff27-e4cac5339f52"
      },
      "outputs": [],
      "source": [
        "model_ckpt = \"google/vivit-b-16x2-kinetics400\"\n",
        "image_processor = VivitImageProcessor.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "16zZty8r1etd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class MyCSVDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        # read csv_file\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get data item according to the index\n",
        "        sample = self.data.iloc[idx]\n",
        "        clip_path = sample['start_frame']\n",
        "        file_name, parent_folder = get_file_name_and_parent_folder(clip_path)\n",
        "        file_name = int(file_name)\n",
        "        frames=[]\n",
        "        for i in range(32):\n",
        "            if (file_name<10):\n",
        "                frame_path = parent_folder + \"/000\" + str(file_name)+ \".png\"\n",
        "            elif (10<=file_name<100):\n",
        "                frame_path = parent_folder + \"/00\" + str(file_name)+ \".png\"\n",
        "            else:\n",
        "                frame_path = parent_folder + \"/0\" + str(file_name)+ \".png\"\n",
        "\n",
        "            # the frames path, adjust it if needed\n",
        "            frame_path = \"../Dataset\" + frame_path[1:]\n",
        "          \n",
        "            frame = Image.open(frame_path).convert('RGB')\n",
        "            frames.append(frame)\n",
        "            file_name += 1\n",
        "\n",
        "        inputs = image_processor(list(frames), return_tensors=\"pt\")\n",
        "        # pixel_values = pixel_values.squeeze(1)\n",
        "\n",
        "        label=sample['arousal_change']\n",
        "        label=label2id[label]\n",
        "        label_numpy = np.array([label])\n",
        "        label_tensor = torch.from_numpy(label_numpy)\n",
        "        label_tensor=torch.LongTensor(label_tensor)\n",
        "        inputs['label']=label_tensor\n",
        "\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "\n",
        "dataset = MyCSVDataset(new_csv_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eKFfTWq2hKe"
      },
      "source": [
        "Split train and test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "YrYyJ10226h7"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "    dataset, [10240, 2560]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am8hyhjz29Vp"
      },
      "source": [
        "dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_GHjNnUs21jn"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# training\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4)\n",
        "# testing\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlUc7JmR3FXv"
      },
      "source": [
        "training or finetuning helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aSqUEgaQ25NH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# from PIL import Image\n",
        "\n",
        "# plot helper\n",
        "def plot(loss_list, output_path):\n",
        "    plt.figure(figsize=(10,5))\n",
        "\n",
        "    freqs = [i for i in range(len(loss_list))]\n",
        "    # Plotting training loss curves\n",
        "    plt.plot(freqs, loss_list, color='#e4007f', label=\"train/loss curve\")\n",
        "\n",
        "    # Plotting axes and legends\n",
        "    plt.ylabel(\"loss\", fontsize='large')\n",
        "    plt.xlabel(\"epoch\", fontsize='large')\n",
        "    plt.legend(loc='upper right', fontsize='x-large')\n",
        "\n",
        "    plt.savefig(output_path+'/pytorch_vivit_loss_curve.png')\n",
        "    # plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfV5cKAr4QaQ"
      },
      "outputs": [],
      "source": [
        "model = VivitForVideoClassification.from_pretrained(\n",
        "    model_ckpt,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test before finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test\n",
        "correct = 0\n",
        "total = 0\n",
        "pred_result = []\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for idx, batch in enumerate(test_dataloader):\n",
        "      \n",
        "      pixel_values = batch.pop(\"pixel_values\").to(device)\n",
        "      pixel_values = pixel_values.squeeze(1)\n",
        "      label = batch.pop(\"label\").to(device)\n",
        "\n",
        "      outputs = model(pixel_values=pixel_values)\n",
        "      logits = outputs.logits\n",
        "      predicted_id = logits.argmax(-1).item()\n",
        "      predicted_label = model.config.id2label[predicted_id]\n",
        "      pred_result.append([idx,predicted_label])\n",
        "      total += label.size(0)\n",
        "      correct += (predicted_id == label).sum().item()\n",
        "acc = correct / total\n",
        "print(\"accuracy:\",acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the accuarcy\n",
        "with open('acc.txt', 'a') as f:\n",
        "    f.write('vivit_wo_finetuning:\\n')\n",
        "    f.write(str(acc))\n",
        "    f.write('\\n')\n",
        "\n",
        "print(\"successfully recorded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dVfHfUx3O_p"
      },
      "source": [
        "finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyDwo_c13Zqp"
      },
      "outputs": [],
      "source": [
        "# lr, epoch can be changed\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "train_size=len(train_dataset)\n",
        "model.to(device)\n",
        "model.train()\n",
        "loss_list = []\n",
        "for epoch in range(6):\n",
        "    print(\"Epoch:\", epoch)\n",
        "    sum_loss_list = []\n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "        pixel_values = batch.pop(\"pixel_values\").to(device)\n",
        "        pixel_values = pixel_values.squeeze(1)\n",
        "        label = batch.pop(\"label\").to(device)\n",
        "\n",
        "        outputs = model(pixel_values=pixel_values,labels=label)\n",
        "        loss = outputs.loss\n",
        "        print(\"Epoch:\",epoch,\" , idx:\",idx,\" , Loss:\", loss.item())\n",
        "        sum_loss_list.append(float(loss.item()))\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    avg_sum_loss = sum(sum_loss_list)/len(sum_loss_list)\n",
        "    print(\"epoch: \", epoch, \"loss: \", float(avg_sum_loss))\n",
        "    loss_list.append(float(avg_sum_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHJqJLFR3m_X"
      },
      "outputs": [],
      "source": [
        "# save model and loss fig, name changed accordingly\n",
        "model_id = './TrainedModels/finetuned_vivit_5epoch'\n",
        "if not os.path.exists(model_id):\n",
        "    os.makedirs(model_id)\n",
        "print(\"model_output:\", model_id)\n",
        "model.save_pretrained(model_id)\n",
        "plot(loss_list, model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Test finetuned vivit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "pred_result = []\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for idx, batch in enumerate(test_dataloader):\n",
        "      pixel_values = batch.pop(\"pixel_values\").to(device)\n",
        "      pixel_values = pixel_values.squeeze(1)\n",
        "      label = batch.pop(\"label\").to(device)\n",
        "      outputs = model(pixel_values=pixel_values)\n",
        "      logits = outputs.logits\n",
        "      predicted_id = logits.argmax(-1).item()\n",
        "      predicted_label = model.config.id2label[predicted_id]\n",
        "      pred_result.append([idx,predicted_label])\n",
        "      total += label.size(0)\n",
        "      correct += (predicted_id == label).sum().item()\n",
        "acc = correct / total\n",
        "print(\"accuracy:\",acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the accuarcy\n",
        "with open('acc.txt', 'a') as f:\n",
        "    # change the name accordingly\n",
        "    f.write('vivit_finetuned_5epochs:\\n')\n",
        "    f.write(str(acc))\n",
        "    f.write('\\n')\n",
        "\n",
        "print(\"successfully recorded\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "22947679820b45cb8a9322acb563e384": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "292a7e5a68094eb98ca3353dcff5c95e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57568d0f8b844d2a9de59b973f2cf656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "593975c3684e477b8f8401d8d571f06d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e969f77d7eb1440d92e1268a2df1a37f",
              "IPY_MODEL_82fdbb9fbfd0490f9bec2d5edd0fa789",
              "IPY_MODEL_c58d5e8298cb432aa9f67cad091498ed"
            ],
            "layout": "IPY_MODEL_292a7e5a68094eb98ca3353dcff5c95e"
          }
        },
        "82fdbb9fbfd0490f9bec2d5edd0fa789": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a46e31db691642d49fe5eed5dc1c4ad1",
            "max": 430,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c70ad00e07e743b694a4ea19fcf8366f",
            "value": 430
          }
        },
        "a46e31db691642d49fe5eed5dc1c4ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c58d5e8298cb432aa9f67cad091498ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de740fe7dc004b6c8d0b7398747e19c9",
            "placeholder": "​",
            "style": "IPY_MODEL_22947679820b45cb8a9322acb563e384",
            "value": " 430/430 [00:00&lt;00:00, 24.8kB/s]"
          }
        },
        "c70ad00e07e743b694a4ea19fcf8366f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc72ba0cbcef40ce8d9c82432487f7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de740fe7dc004b6c8d0b7398747e19c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e969f77d7eb1440d92e1268a2df1a37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57568d0f8b844d2a9de59b973f2cf656",
            "placeholder": "​",
            "style": "IPY_MODEL_cc72ba0cbcef40ce8d9c82432487f7b7",
            "value": "preprocessor_config.json: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
